@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}
@article{mcmahan2010adaptive,
  title={Adaptive bound optimization for online convex optimization},
  author={McMahan, H Brendan and Streeter, Matthew},
  journal={arXiv preprint arXiv:1002.4908},
  year={2010}
}
@article{shalev2012online,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={4},
  number={2},
  pages={107--194},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@techreport{McMahan2014,
abstract = {We present tools for the analysis of Follow-The-Regularized-Leader (FTRL), Dual Averaging, and Mirror Descent algorithms when the regularizer (equivalently, prox-function or learning rate schedule) is chosen adaptively based on the data. Adaptivity can be used to prove regret bounds that hold on every round, and also allows for data-dependent regret bounds as in AdaGrad-style algorithms (e.g., Online Gradient Descent with adaptive per-coordinate learning rates). We present results from a large number of prior works in a unified manner, using a modular and tight analysis that isolates the key arguments in easily re-usable lemmas. This approach strengthens pre-viously known FTRL analysis techniques to produce bounds as tight as those achieved by potential functions or primal-dual analysis. Further, we prove a general and exact equivalence between an arbitrary adaptive Mirror Descent algorithm and a correspond- ing FTRL update, which allows us to analyze any Mirror Descent algorithm in the same framework. The key to bridging the gap between Dual Averaging and Mirror Descent algorithms lies in an analysis of the FTRL-Proximal algorithm family. Our regret bounds are proved in the most general form, holding for arbitrary norms and non-smooth regularizers with time-varying weight.},
archivePrefix = {arXiv},
arxivId = {1403.3465},
author = {McMahan, H. Brendan},
booktitle = {Journal of Machine Learning Research},
doi = {10.1016/j.chroma.2010.08.034},
eprint = {1403.3465},
file = {:Users/liuzhiwei/Library/Application Support/Mendeley Desktop/Downloaded/Mcmahan - 2017 - A Survey of Algorithms and Analysis for Adaptive Online Learning.pdf:pdf},
isbn = {0021-9673},
issn = {15337928},
keywords = {adaptive algorithms,dual averaging,follow-the-regularized-leader,mirror descent,online convex optimization,online learning,regret analysis},
mendeley-groups = {ML/MasterThesis},
pages = {1--50},
pmid = {20817166},
title = {{A Survey of Algorithms and Analysis for Adaptive Online Learning}},
url = {http://arxiv.org/abs/1403.3465},
volume = {18},
year = {2014}
}
@article{Cutkosky2017,
    archivePrefix = {arXiv},
    arxivId = {1703.02629},
    author = {Cutkosky, Ashok and Boahen, Kwabena},
    eprint = {1703.02629},
    isbn = {1703.02629v2},
    journal = {Proceedings of Machine Learning Research},
    keywords = {()},
    mendeley-groups = {MasterThesis},
    pages = {1--35},
    title = {{Online Learning Without Prior Information}},
    url = {https://arxiv.org/pdf/1703.02629.pdf},
    volume = {65},
    year = {2017}
}
@article{Orabona2016,
abstract = {In the recent years, a number of parameter-free algorithms have been developed for online linear optimization over Hilbert spaces and for learning with expert advice. These algorithms achieve optimal regret bounds that depend on the unknown competitors, without having to tune the learning rates with oracle choices. We present a new intuitive framework to design parameter-free algorithms for $\backslash$emph{\{}both{\}} online linear optimization over Hilbert spaces and for learning with expert advice, based on reductions to betting on outcomes of adversarial coins. We instantiate it using a betting algorithm based on the Krichevsky-Trofimov estimator. The resulting algorithms are simple, with no parameters to be tuned, and they improve or match previous results in terms of regret guarantee and per-round complexity.},
archivePrefix = {arXiv},
arxivId = {1602.04128},
author = {Orabona, Francesco and P{\'{a}}l, D{\'{a}}vid},
eprint = {1602.04128},
file = {:Users/liuzhiwei/Library/Application Support/Mendeley Desktop/Downloaded/Orabona, P{\'{a}}l - 2016 - Coin Betting and Parameter-Free Online Learning.pdf:pdf},
issn = {10495258},
mendeley-groups = {MasterThesis},
month = {feb},
title = {{Coin Betting and Parameter-Free Online Learning}},
url = {http://arxiv.org/abs/1602.04128},
year = {2016}
}
@incollection{Cutkosky2016,
abstract = {We propose an online convex optimization algorithm (RescaledExp) that achieves optimal regret in the unconstrained setting without prior knowledge of any bounds on the loss functions. We prove a lower bound showing an exponential separation between the regret of existing algorithms that require a known bound on the loss functions and any algorithm that does not require such knowledge. RescaledExp matches this lower bound asymptotically in the number of iterations. RescaledExp is naturally hyperparameter-free and we demonstrate empirically that it matches prior optimization algorithms that require hyperparameter optimization.},
author = {Cutkosky, Ashok and Boahen, Kwabena A},
booktitle = {Advances in Neural Information Processing Systems 29},
issn = {10495258},
title = {{Online Convex Optimization with Unconstrained Domains and Losses}},
year = {2016}
}
@article{McMahan2013,
abstract = {We design and analyze minimax-optimal algorithms for online linear optimization games where the player's choice is unconstrained. The player strives to minimize regret, the difference between his loss and the loss of a post-hoc benchmark strategy. The standard benchmark is the loss of the best strategy chosen from a bounded comparator set. When the the comparison set and the adversary's gradients satisfy L{\_}infinity bounds, we give the value of the game in closed form and prove it approaches sqrt(2T/pi) as T -{\textgreater} infinity. Interesting algorithms result when we consider soft constraints on the comparator, rather than restricting it to a bounded set. As a warmup, we analyze the game with a quadratic penalty. The value of this game is exactly T/2, and this value is achieved by perhaps the simplest online algorithm of all: unprojected gradient descent with a constant learning rate. We then derive a minimax-optimal algorithm for a much softer penalty function. This algorithm achieves good bounds under the standard notion of regret for any comparator point, without needing to specify the comparator set in advance. The value of this game converges to sqrt{\{}e{\}} as T -{\textgreater}infinity; we give a closed-form for the exact value as a function of T. The resulting algorithm is natural in unconstrained investment or betting scenarios, since it guarantees at worst constant loss, while allowing for exponential reward against an "easy" adversary.},
archivePrefix = {arXiv},
arxivId = {1302.2176},
author = {McMahan, H. B. and Abernethy, J.},
eprint = {1302.2176},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems 26 (NIPS)},
title = {{Minimax optimal algorithms for unconstrained linear optimization}},
year = {2013}
}
@inproceedings{orabona2014simultaneous,
  title={Simultaneous model selection and optimization through parameter-free stochastic learning},
  author={Orabona, Francesco},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1116--1124},
  year={2014}
}

@article{Cutkosky2018,
abstract = {We introduce several new black-box reductions that significantly improve the design of adaptive and parameter-free online learning algorithms by simplifying analysis, improving regret guarantees, and sometimes even improving runtime. We reduce parameter-free online learning to online exp-concave optimization, we reduce optimization in a Banach space to one-dimensional optimization, and we reduce optimization over a constrained domain to unconstrained optimization. All of our reductions run as fast as online gradient descent. We use our new techniques to improve upon the previously best regret bounds for parameter-free learning, and do so for arbitrary norms.},
archivePrefix = {arXiv},
arxivId = {1802.06293},
author = {Cutkosky, Ashok and Orabona, Francesco},
doi = {http://dx.doi.org/10.2166/wh.2016.230},
eprint = {1802.06293},
file = {:Users/liuzhiwei/Library/Application Support/Mendeley Desktop/Downloaded/Cutkosky, Orabona - 2018 - Black-Box Reductions for Parameter-free Online Learning in Banach Spaces.pdf:pdf},
issn = {1477-8920},
mendeley-groups = {MasterThesis},
month = {feb},
title = {{Black-Box Reductions for Parameter-free Online Learning in Banach Spaces}},
url = {http://arxiv.org/abs/1802.06293},
year = {2018}
}

@article{Orabona2017,
abstract = {Deep learning methods achieve state-of-the-art performance in many application scenarios. Yet, these methods require a significant amount of hyperparameters tuning in order to achieve the best results. In particular, tuning the learning rates in the stochastic optimization process is still one of the main bottlenecks. In this paper, we propose a new stochastic gradient descent procedure for deep networks that does not require any learning rate setting. Contrary to previous methods, we do not adapt the learning rates nor we make use of the assumed curvature of the objective function. Instead, we reduce the optimization process to a game of betting on a coin and propose a learning-rate-free optimal algorithm for this scenario. Theoretical convergence is proven for convex and quasi-convex functions and empirical evidence shows the advantage of our algorithm over popular stochastic gradient algorithms.},
archivePrefix = {arXiv},
arxivId = {1705.07795},
author = {Orabona, Francesco and Tommasi, Tatiana},
eprint = {1705.07795},
issn = {10495258},
mendeley-groups = {MasterThesis},
month = {may},
title = {{Training Deep Networks without Learning Rates Through Coin Betting}},
url = {http://arxiv.org/abs/1705.07795},
year = {2017}
}

@article{Hazan2015,
abstract = {The graduated optimization approach, also known as the continuation method, is a popular heuristic to solving non-convex problems that has received renewed interest over the last decade. Despite its popularity, very little is known in terms of theoretical convergence analysis. In this paper we describe a new first-order algorithm based on graduated optimiza- tion and analyze its performance. We characterize a parameterized family of non- convex functions for which this algorithm provably converges to a global optimum. In particular, we prove that the algorithm converges to an {\{}$\backslash$epsilon{\}}-approximate solution within O(1/$\backslash$epsilon{\^{}}2) gradient-based steps. We extend our algorithm and analysis to the setting of stochastic non-convex optimization with noisy gradient feedback, attaining the same convergence rate. Additionally, we discuss the setting of zero-order optimization, and devise a a variant of our algorithm which converges at rate of O(d{\^{}}2/$\backslash$epsilon{\^{}}4).},
archivePrefix = {arXiv},
arxivId = {1503.03712},
author = {Hazan, Elad and Levy, Kfir Y. and Shalev-Shwartz, Shai},
doi = {10.1016/S0269-7491(03)00143-X},
eprint = {1503.03712},
file = {:Users/liuzhiwei/Library/Application Support/Mendeley Desktop/Downloaded/Hazan, Levy, Shalev-Shwartz - 2015 - On Graduated Optimization for Stochastic Non-Convex Problems.pdf:pdf},
isbn = {9781510829008},
issn = {0269-7491},
mendeley-groups = {MasterThesis},
month = {mar},
pmid = {12860105},
title = {{On Graduated Optimization for Stochastic Non-Convex Problems}},
url = {http://arxiv.org/abs/1503.03712},
year = {2015}
}

@article{Bartlett2007,
abstract = {We study the rates of growth of the regret in online convex optimization. First, we show that a simple extension of the algorithm of Hazan et al eliminates the need for a priori knowledge of the lower bound on the second derivatives of the observed functions. We then provide an algorithm, Adaptive Online Gradient Descent, which interpolates between the results of Zinkevich for linear functions and of Hazan et al for strongly convex functions, achieving intermediate rates between âˆš T and log T . Furthermore, we show strong optimality of the algorithm. Finally, we provide an extension of our results to general norms.},
author = {Bartlett, Peter L and Hazan, Elad and Rakhlin, Alexander},
file = {:Users/liuzhiwei/Library/Application Support/Mendeley Desktop/Downloaded/Bartlett, Hazan, Rakhlin - Unknown - Adaptive Online Gradient Descent.pdf:pdf},
isbn = {160560352X},
journal = {Advances in neural information processing systems},
mendeley-groups = {ML/MasterThesis},
pages = {1--8},
title = {{Adaptive Online Gradient Descent}},
url = {http://papers.nips.cc/paper/3319-adaptive-online-gradient-descent.pdf},
volume = {13},
year = {2007}
}

@article{Allen-Zhu2017,
abstract = {We design a stochastic algorithm to train any smooth neural network to {\$}\backslashvarepsilon{\$}-approximate local minima, using {\$}O(\backslashvarepsilon{\^{}}{\{}-3.25{\}}){\$} backpropagations. The best result was essentially {\$}O(\backslashvarepsilon{\^{}}{\{}-4{\}}){\$} by SGD. More broadly, it finds {\$}\backslashvarepsilon{\$}-approximate local minima of any smooth nonconvex function in rate {\$}O(\backslashvarepsilon{\^{}}{\{}-3.25{\}}){\$}, with only oracle access to stochastic gradients.},
archivePrefix = {arXiv},
arxivId = {1708.08694},
author = {Allen-Zhu, Zeyuan},
doi = {10.1177/1077699015607337},
eprint = {1708.08694},
file = {:Users/liuzhiwei/Library/Application Support/Mendeley Desktop/Downloaded/Allen-Zhu - Unknown - Natasha 2 Faster Non-Convex Optimization Than SGD.pdf:pdf},
isbn = {1365-2753 (Electronic)$\backslash$r1356-1294 (Linking)},
issn = {1702.00763},
mendeley-groups = {ML/MasterThesis},
pmid = {20626538},
title = {{Natasha 2: Faster Non-Convex Optimization Than SGD}},
url = {https://arxiv.org/abs/1708.08694. http://arxiv.org/abs/1708.08694},
year = {2017}
}

@article{OPT-013,
author = {Hazan, Elad},
doi = {10.1561/2400000013},
issn = {2167-3888},
journal = {Foundations and Trends{\textregistered} in Optimization},
mendeley-groups = {ML/MasterThesis},
number = {3-4},
pages = {157--325},
title = {{Introduction to Online Convex Optimization}},
url = {http://dx.doi.org/10.1561/2400000013},
volume = {2},
year = {2016}
}

@article{Agarwal2016,
abstract = {We design a non-convex second-order optimization algorithm that is guaranteed to return an approximate local minimum in time which scales linearly in the underlying dimension and the number of training examples. The time complexity of our algorithm to find an approximate local minimum is even faster than that of gradient descent to find a critical point. Our algorithm applies to a general class of optimization problems including training a neural network and other non-convex objectives arising in machine learning.},
archivePrefix = {arXiv},
arxivId = {1611.01146},
author = {Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian and Hazan, Elad and Ma, Tengyu},
doi = {10.1145/3055399.3055464},
eprint = {1611.01146},
file = {:Users/liuzhiwei/Library/Application Support/Mendeley Desktop/Downloaded/Agarwal et al. - 2016 - Finding Approximate Local Minima Faster than Gradient Descent Institute for Advanced Study.pdf:pdf},
isbn = {9781450345286},
issn = {07378017},
mendeley-groups = {ML/MasterThesis},
title = {{Finding Approximate Local Minima Faster than Gradient Descent}},
url = {https://arxiv.org/pdf/1611.01146.pdf http://arxiv.org/abs/1611.01146},
year = {2016}
}
